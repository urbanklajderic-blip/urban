// SDK exports these request functions:
//
//   /**
//    * Create a chat completion
//    */
//
//   export function createChatCompletion(opts: CreateChatCompletionData): Promise<{
//     error?: CreateChatCompletionErrors[keyof CreateChatCompletionErrors],
//     data?: CreateChatCompletionResponses[keyof CreateChatCompletionResponses],
//     request: Request,
//     response: Response }>;
//
//   ALIAS: createChatCompletion is equivalent to: import { requestOpenAIGPTChat } from '@/sdk/api-clients/688a0b64dc79a2533460892c/requestOpenAIGPTChat'
//
// 

export type ClientOptions = {
    baseUrl: 'https://genaiapi.cloudsway.net' | (string & {});
};

export type CreateChatCompletionData = {
    body: {
        /**
         * Model name
         */
        model: string;
        /**
         * Conversation history
         */
        messages: Array<{
            role: 'system' | 'user' | 'assistant';
            content: string;
        }>;
    };
    path?: never;
    query?: never;
    url: '/v1/ai/zWwyutGgvEGWwzSa/chat/completions';
};

export type CreateChatCompletionErrors = {
    /**
     * Invalid or missing API key
     */
    401: unknown;
    /**
     * Client error
     */
    '4XX': unknown;
    /**
     * Server error
     */
    '5XX': unknown;
};

export type CreateChatCompletionResponses = {
    /**
     * Successful completion
     */
    200: {
        /**
         * A unique identifier for the chat completion
         */
        id: string;
        /**
         * The object type, which is always 'chat.completion'
         */
        object: 'chat.completion';
        /**
         * The Unix timestamp (in seconds) of when the chat completion was created
         */
        created: number;
        /**
         * The model used for the chat completion
         */
        model: string;
        /**
         * This fingerprint represents the backend configuration that the model runs with
         */
        system_fingerprint?: string | null;
        /**
         * A list of chat completion choices. Can be more than one if n is greater than 1
         */
        choices: Array<{
            /**
             * The index of the choice in the list of choices
             */
            index: number;
            /**
             * Log probability information for the choice
             */
            logprobs?: {
                [key: string]: unknown;
            } | null;
            message: {
                /**
                 * The role of the author of this message
                 */
                role: 'assistant';
                /**
                 * The contents of the message
                 */
                content: string;
                /**
                 * The reasoning content of the message, if any
                 */
                reasoning_content?: string | null;
                /**
                 * The function call generated by the model, if any
                 */
                function_call?: {
                    [key: string]: unknown;
                } | null;
                /**
                 * The tool calls generated by the model, if any
                 */
                tool_calls?: Array<{
                    [key: string]: unknown;
                }> | null;
                /**
                 * Additional reasoning details, if any
                 */
                reasoning_details?: {
                    [key: string]: unknown;
                } | null;
            };
            /**
             * The reason the model stopped generating tokens
             */
            finish_reason: 'stop' | 'length' | 'function_call' | 'content_filter' | 'null';
            /**
             * The native finish reason from the underlying model
             */
            native_finish_reason?: string | null;
        }>;
        /**
         * Usage statistics for the completion request
         */
        usage: {
            /**
             * Number of tokens in the prompt
             */
            prompt_tokens: number;
            /**
             * Number of tokens in the generated completion
             */
            completion_tokens: number;
            /**
             * Total number of tokens used in the request (prompt + completion)
             */
            total_tokens: number;
            /**
             * Breakdown of completion tokens usage
             */
            completion_tokens_details?: {
                /**
                 * Number of tokens used for reasoning
                 */
                reasoning_tokens: number;
            };
            /**
             * Breakdown of prompt tokens usage
             */
            prompt_tokens_details?: {
                [key: string]: unknown;
            } | null;
        };
    };
};

export type CreateChatCompletionResponse = CreateChatCompletionResponses[keyof CreateChatCompletionResponses];
